import os
import re
from collections import defaultdict
import pandas as pd

def match_custom_dictionaries(
    df,
    text_column,
    dict_dir,
    dict_names,
    show_details=True
):
    """
    –ò—â–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Å–ª–æ–≤–∞—Ä—è–º–∏ –≤ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö.
    –í–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—Å—Ç—Ä–æ–µ–Ω —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Ñ—Ä–∞–∑–µ–æ–ª–æ–≥–∏–∑–º–æ–≤.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    - df: pandas DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π –ª–µ–º–º
    - text_column: –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º (—Å—Ç—Ä–æ–∫–∞)
    - dict_dir: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ, –≥–¥–µ –ª–µ–∂–∞—Ç —Å–ª–æ–≤–∞—Ä–∏ (—Ñ–∞–π–ª—ã –≤–∏–¥–∞ name_lemm.txt)
    - dict_names: —Å–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –∏–º–µ–Ω —Å–ª–æ–≤–∞—Ä–µ–π (–±–µ–∑ _lemm.txt)
    - show_details: –≤—ã–≤–æ–¥–∏—Ç—å –ª–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - total_matches: —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –≤—Å–µ—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    - unique_matches: —Å–ª–æ–≤–∞—Ä—å —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏
    """

    # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Ñ—Ä–∞–∑–µ–æ–ª–æ–≥–∏–∑–º–æ–≤
    compound_patterns = [ 
        r'–±—Ä–æ—Å–∞—Ç—å –∫–∞–º–Ω–∏ –≤ \S+ –æ–≥–æ—Ä–æ–¥',
        r'–≤–∏—Ç—å –∏–∑ \S+ –≤–µ—Ä—ë–≤–∫–∏',
        r'–≤—ã–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å \S+ —Ä—É–∫–∏',
        r'–¥–æ—Å—Ç–∞–≤–∞—Ç—å \S+',
        r'–∑–∞–±–∏—Ç—å –Ω–∞ \S+',
        r'–∑–∞–≤—è–∑–∞—Ç—å —Å \S+',
        r'–∑–∞–≥–Ω–∞—Ç—å \S+ –≤ —É–≥–æ–ª',
        r'–∑–∞–∫—Ä—ã–≤–∞—Ç—å –≥–ª–∞–∑–∞ –Ω–∞ \S+',
        r'–∑–∞—Ç–º–∏—Ç—å \S+',
        r'–ª–µ–±–µ–∑–∏—Ç—å –ø–µ—Ä–µ–¥ \S+',
        r'–º–µ—Ä–∏—Ç—å –≤—Å–µ—Ö –Ω–∞ \S+ –∞—Ä—à–∏–Ω',
        r'–Ω–µ –ø–æ \S+ —á–∞—Å—Ç–∏',
        r'–æ—Ç–ø—Ä–∞–≤–∏—Ç—å \S+ –∫ –ø—Ä–∞–æ—Ç—Ü–∞–º',
        r'–æ—Ç–ø—Ä–∞–≤–∏—Ç—å \S+ –Ω–∞ —Ç–æ—Ç —Å–≤–µ—Ç',
        r'–ø–µ—Ä–µ–º—ã–≤–∞—Ç—å \S+ –∫–æ—Å—Ç–æ—á–∫–∏',
        r'–ø–ª–∞–∫–∞—Ç—å \S+ –≤ –∂–∏–ª–µ—Ç–∫—É',
        r'–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å \S+ –ø–æ –¥—É—à–∞–º',
        r'–ø–æ–¥—Å—Ç–∞–≤–ª—è—Ç—å \S+ –ø–æ–¥ —É–¥–∞—Ä',
        r'–ø–æ–∫–∞–∑–∞—Ç—å \S+ –≥–¥–µ —Ä–∞–∫–∏ –∑–∏–º—É—é—Ç',
        r'–ø–æ–∫–∞–∑–∞—Ç—å \S+ –∫—É–∑—å–∫–∏–Ω—É –º–∞—Ç—å',
        r'–ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–µ–±—è –≤ \S+',
        r'–ø—Ä–∏–Ω–∏–º–∞—Ç—å \S+ –∑–∞ —á–∏—Å—Ç—É—é –º–æ–Ω–µ—Ç—É',
        r'–ø—Ä–æ–ø—É—Å–∫–∞—Ç—å \S+ –º–∏–º–æ —É—à–µ–π',
        r'–ø—Ä–æ—Ç—è–Ω—É—Ç—å \S+ —Ä—É–∫—É –ø–æ–º–æ—â–∏',
        r'–ø—É—Å–∫–∞—Ç—å \S+ –ø—ã–ª—å –≤ –≥–ª–∞–∑–∞',
        r'—Ä–∞–∑–≤—è–∑–∞—Ç—å \S+ —Ä—É–∫–∏',
        r'—Ä—ã—Ç—å—Å—è –≤ \S+ –≥—Ä—è–∑–Ω–æ–º –±–µ–ª—å–µ',
        r'—Å–±–∏—Ç—å \S+ —Å –ø–∞–Ω—Ç–∞–ª—ã–∫—É',
        r'—Å–≤—è–∑–∞—Ç—å \S+ –ø–æ —Ä—É–∫–∞–º –∏ –Ω–æ–≥–∞–º',
        r'—Å–≤—è–∑—ã–≤–∞—Ç—å—Å—è —Å \S+',
        r'—Å–¥–µ–ª–∞—Ç—å \S+ –æ—Ä—É–¥–∏–µ–º –≤ —Å–≤–æ–∏—Ö —Ä—É–∫–∞—Ö',
        r'—Å–∫–∏–¥—ã–≤–∞—Ç—å—Å—è –Ω–∞ \S+',
        r'—Å—Ç–µ—Ä–µ—Ç—å \S+ –≤ –ø–æ—Ä–æ—à–æ–∫',
        r'—Å—É–¥—å–±–∞ —É–ª—ã–±–∞–µ—Ç—Å—è \S+',
        r'—Ç–∏–ø—É–Ω \S+ –Ω–∞ —è–∑—ã–∫'
    ]

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π –∏–∑ —Ñ–∞–π–ª–æ–≤
    phrase_dicts = {
        name: {
            line.strip()
            for line in open(os.path.join(dict_dir, f"{name}_lemm.txt"), encoding='utf-8')
        }
        for name in dict_names
    }

    # –î–æ–±–∞–≤–ª—è–µ–º "—Å–ª–æ–≤–∞—Ä—å" –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    phrase_dicts['phraseologisms_compound'] = set(compound_patterns)

    print("–ó–∞–≥—Ä—É–∂–µ–Ω—ã —Å–ª–æ–≤–∞—Ä–∏:")
    for name, word_set in phrase_dicts.items():
        print(f"  {name}: {len(word_set)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

    total_matches = defaultdict(int)
    unique_matches = defaultdict(set)

    for text in df[text_column]:
        words = set(text.split())
        joined_text = ' '.join(words)

        for category, dictionary in phrase_dicts.items():
            if category == 'phraseologisms_compound':
                for pattern in compound_patterns:
                    match = re.search(pattern, joined_text)
                    if match:
                        total_matches[category] += 1
                        unique_matches[category].add(match.group(0))
            else:
                matches = words & dictionary
                total_matches[category] += len(matches)
                unique_matches[category].update(matches)

    print("\n–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è:")
    for category in phrase_dicts.keys():
        print(f"\nüìö –°–ª–æ–≤–∞—Ä—å: {category}")
        print(f"–í—Å–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matches[category]}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(unique_matches[category])}")
        if show_details:
            print("–°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π:")
            print(', '.join(sorted(unique_matches[category])) if unique_matches[category] else "–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
        print("-" * 50)

    return total_matches, unique_matches
